{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "myPersonalityTextRegression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1f4dPOd-P2BgazfoBS9zD4cZGP8z2H7LP",
      "authorship_tag": "ABX9TyO31NrHsCosqa9xmgAxzMW3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yudhiesh/PyTorch/blob/master/myPersonalityTextRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUgN4FSUuiil",
        "outputId": "42eff443-515a-4dd9-a41c-ede39d6af6e0"
      },
      "source": [
        "!pip install transformers==3\n",
        "!pip install pytorch-lightning"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers==3 in /usr/local/lib/python3.6/dist-packages (3.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==3) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3) (2.23.0)\n",
            "Requirement already satisfied: tokenizers==0.8.0-rc4 in /usr/local/lib/python3.6/dist-packages (from transformers==3) (0.8.0rc4)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==3) (0.0.43)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==3) (4.41.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers==3) (0.1.95)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==3) (0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3) (20.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3) (3.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3) (1.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3) (2.4.7)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.6/dist-packages (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (4.41.1)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (0.18.2)\n",
            "Requirement already satisfied: fsspec[http]>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (0.8.5)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (2.4.1)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (1.7.0+cu101)\n",
            "Requirement already satisfied: PyYAML!=5.4.*,>=5.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (5.3.1)\n",
            "Requirement already satisfied: requests; extra == \"http\" in /usr/local/lib/python3.6/dist-packages (from fsspec[http]>=0.8.1->pytorch-lightning) (2.23.0)\n",
            "Requirement already satisfied: aiohttp; extra == \"http\" in /usr/local/lib/python3.6/dist-packages (from fsspec[http]>=0.8.1->pytorch-lightning) (3.7.3)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.12.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.3.3)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.25.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (53.0.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.36.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.0.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.10.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.4.2)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.32.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.8.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->pytorch-lightning) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->pytorch-lightning) (0.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning) (2.10)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.6/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning) (5.1.0)\n",
            "Requirement already satisfied: idna-ssl>=1.0; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning) (1.1.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning) (20.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning) (1.6.3)\n",
            "Requirement already satisfied: async-timeout<4.0,>=3.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning) (3.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (3.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.7)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (3.4.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFPIZs9Xzp01"
      },
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, multilabel_confusion_matrix, classification_report\n",
        "from torch import cuda"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yALDMHuHurn0"
      },
      "source": [
        "PATH = \"/content/drive/MyDrive/BLI_Data/data.csv\"\n",
        "df = pd.read_csv(PATH)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 730
        },
        "id": "QsiO5Fz5uz9v",
        "outputId": "b747fd3f-9d15-46c8-98f1-4bb56d541392"
      },
      "source": [
        "df.head(10)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>#AUTHID</th>\n",
              "      <th>STATUS</th>\n",
              "      <th>sEXT</th>\n",
              "      <th>sNEU</th>\n",
              "      <th>sAGR</th>\n",
              "      <th>sCON</th>\n",
              "      <th>sOPN</th>\n",
              "      <th>cEXT</th>\n",
              "      <th>cNEU</th>\n",
              "      <th>cAGR</th>\n",
              "      <th>cCON</th>\n",
              "      <th>cOPN</th>\n",
              "      <th>DATE</th>\n",
              "      <th>NETWORKSIZE</th>\n",
              "      <th>BETWEENNESS</th>\n",
              "      <th>NBETWEENNESS</th>\n",
              "      <th>DENSITY</th>\n",
              "      <th>BROKERAGE</th>\n",
              "      <th>NBROKERAGE</th>\n",
              "      <th>TRANSITIVITY</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
              "      <td>likes the sound of thunder.</td>\n",
              "      <td>2.65</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.15</td>\n",
              "      <td>3.25</td>\n",
              "      <td>4.4</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>06/19/09 03:21 PM</td>\n",
              "      <td>180.0</td>\n",
              "      <td>14861.6</td>\n",
              "      <td>93.29</td>\n",
              "      <td>0.03</td>\n",
              "      <td>15661.0</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
              "      <td>is so sleepy it's not even funny that's she ca...</td>\n",
              "      <td>2.65</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.15</td>\n",
              "      <td>3.25</td>\n",
              "      <td>4.4</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>07/02/09 08:41 AM</td>\n",
              "      <td>180.0</td>\n",
              "      <td>14861.6</td>\n",
              "      <td>93.29</td>\n",
              "      <td>0.03</td>\n",
              "      <td>15661.0</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
              "      <td>is sore and wants the knot of muscles at the b...</td>\n",
              "      <td>2.65</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.15</td>\n",
              "      <td>3.25</td>\n",
              "      <td>4.4</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>06/15/09 01:15 PM</td>\n",
              "      <td>180.0</td>\n",
              "      <td>14861.6</td>\n",
              "      <td>93.29</td>\n",
              "      <td>0.03</td>\n",
              "      <td>15661.0</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
              "      <td>likes how the day sounds in this new song.</td>\n",
              "      <td>2.65</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.15</td>\n",
              "      <td>3.25</td>\n",
              "      <td>4.4</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>06/22/09 04:48 AM</td>\n",
              "      <td>180.0</td>\n",
              "      <td>14861.6</td>\n",
              "      <td>93.29</td>\n",
              "      <td>0.03</td>\n",
              "      <td>15661.0</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
              "      <td>is home. &lt;3</td>\n",
              "      <td>2.65</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.15</td>\n",
              "      <td>3.25</td>\n",
              "      <td>4.4</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>07/20/09 02:31 AM</td>\n",
              "      <td>180.0</td>\n",
              "      <td>14861.6</td>\n",
              "      <td>93.29</td>\n",
              "      <td>0.03</td>\n",
              "      <td>15661.0</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
              "      <td>www.thejokerblogs.com</td>\n",
              "      <td>2.65</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.15</td>\n",
              "      <td>3.25</td>\n",
              "      <td>4.4</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>07/16/09 03:21 PM</td>\n",
              "      <td>180.0</td>\n",
              "      <td>14861.6</td>\n",
              "      <td>93.29</td>\n",
              "      <td>0.03</td>\n",
              "      <td>15661.0</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
              "      <td>saw a nun zombie, and liked it. Also, *PROPNAM...</td>\n",
              "      <td>2.65</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.15</td>\n",
              "      <td>3.25</td>\n",
              "      <td>4.4</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>06/27/09 05:41 AM</td>\n",
              "      <td>180.0</td>\n",
              "      <td>14861.6</td>\n",
              "      <td>93.29</td>\n",
              "      <td>0.03</td>\n",
              "      <td>15661.0</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
              "      <td>is in Kentucky. 421 miles into her 1100 mile j...</td>\n",
              "      <td>2.65</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.15</td>\n",
              "      <td>3.25</td>\n",
              "      <td>4.4</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>07/18/09 06:34 AM</td>\n",
              "      <td>180.0</td>\n",
              "      <td>14861.6</td>\n",
              "      <td>93.29</td>\n",
              "      <td>0.03</td>\n",
              "      <td>15661.0</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
              "      <td>was about to finish a digital painting before ...</td>\n",
              "      <td>2.65</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.15</td>\n",
              "      <td>3.25</td>\n",
              "      <td>4.4</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>07/09/09 02:58 PM</td>\n",
              "      <td>180.0</td>\n",
              "      <td>14861.6</td>\n",
              "      <td>93.29</td>\n",
              "      <td>0.03</td>\n",
              "      <td>15661.0</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
              "      <td>is celebrating her new haircut by listening to...</td>\n",
              "      <td>2.65</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.15</td>\n",
              "      <td>3.25</td>\n",
              "      <td>4.4</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>07/07/09 11:41 PM</td>\n",
              "      <td>180.0</td>\n",
              "      <td>14861.6</td>\n",
              "      <td>93.29</td>\n",
              "      <td>0.03</td>\n",
              "      <td>15661.0</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            #AUTHID  ... TRANSITIVITY\n",
              "0  b7b7764cfa1c523e4e93ab2a79a946c4  ...          0.1\n",
              "1  b7b7764cfa1c523e4e93ab2a79a946c4  ...          0.1\n",
              "2  b7b7764cfa1c523e4e93ab2a79a946c4  ...          0.1\n",
              "3  b7b7764cfa1c523e4e93ab2a79a946c4  ...          0.1\n",
              "4  b7b7764cfa1c523e4e93ab2a79a946c4  ...          0.1\n",
              "5  b7b7764cfa1c523e4e93ab2a79a946c4  ...          0.1\n",
              "6  b7b7764cfa1c523e4e93ab2a79a946c4  ...          0.1\n",
              "7  b7b7764cfa1c523e4e93ab2a79a946c4  ...          0.1\n",
              "8  b7b7764cfa1c523e4e93ab2a79a946c4  ...          0.1\n",
              "9  b7b7764cfa1c523e4e93ab2a79a946c4  ...          0.1\n",
              "\n",
              "[10 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JdM6mLrvBlL"
      },
      "source": [
        "cols = [\"STATUS\", \"sEXT\",\"sNEU\",\"sAGR\",\"sCON\",\"sOPN\"]\n",
        "cols_normalize = [\"sEXT\",\"sNEU\",\"sAGR\",\"sCON\",\"sOPN\"]"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhfykgm_vFuS"
      },
      "source": [
        "df = df[cols]"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "L2x4iSxEvIZ_",
        "outputId": "a3a77183-8540-481d-a251-bb6c6c2baa78"
      },
      "source": [
        "df.head(10)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>STATUS</th>\n",
              "      <th>sEXT</th>\n",
              "      <th>sNEU</th>\n",
              "      <th>sAGR</th>\n",
              "      <th>sCON</th>\n",
              "      <th>sOPN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>likes the sound of thunder.</td>\n",
              "      <td>2.65</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.15</td>\n",
              "      <td>3.25</td>\n",
              "      <td>4.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>is so sleepy it's not even funny that's she ca...</td>\n",
              "      <td>2.65</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.15</td>\n",
              "      <td>3.25</td>\n",
              "      <td>4.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>is sore and wants the knot of muscles at the b...</td>\n",
              "      <td>2.65</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.15</td>\n",
              "      <td>3.25</td>\n",
              "      <td>4.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>likes how the day sounds in this new song.</td>\n",
              "      <td>2.65</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.15</td>\n",
              "      <td>3.25</td>\n",
              "      <td>4.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>is home. &lt;3</td>\n",
              "      <td>2.65</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.15</td>\n",
              "      <td>3.25</td>\n",
              "      <td>4.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>www.thejokerblogs.com</td>\n",
              "      <td>2.65</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.15</td>\n",
              "      <td>3.25</td>\n",
              "      <td>4.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>saw a nun zombie, and liked it. Also, *PROPNAM...</td>\n",
              "      <td>2.65</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.15</td>\n",
              "      <td>3.25</td>\n",
              "      <td>4.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>is in Kentucky. 421 miles into her 1100 mile j...</td>\n",
              "      <td>2.65</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.15</td>\n",
              "      <td>3.25</td>\n",
              "      <td>4.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>was about to finish a digital painting before ...</td>\n",
              "      <td>2.65</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.15</td>\n",
              "      <td>3.25</td>\n",
              "      <td>4.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>is celebrating her new haircut by listening to...</td>\n",
              "      <td>2.65</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.15</td>\n",
              "      <td>3.25</td>\n",
              "      <td>4.4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              STATUS  sEXT  ...  sCON  sOPN\n",
              "0                        likes the sound of thunder.  2.65  ...  3.25   4.4\n",
              "1  is so sleepy it's not even funny that's she ca...  2.65  ...  3.25   4.4\n",
              "2  is sore and wants the knot of muscles at the b...  2.65  ...  3.25   4.4\n",
              "3         likes how the day sounds in this new song.  2.65  ...  3.25   4.4\n",
              "4                                        is home. <3  2.65  ...  3.25   4.4\n",
              "5                              www.thejokerblogs.com  2.65  ...  3.25   4.4\n",
              "6  saw a nun zombie, and liked it. Also, *PROPNAM...  2.65  ...  3.25   4.4\n",
              "7  is in Kentucky. 421 miles into her 1100 mile j...  2.65  ...  3.25   4.4\n",
              "8  was about to finish a digital painting before ...  2.65  ...  3.25   4.4\n",
              "9  is celebrating her new haircut by listening to...  2.65  ...  3.25   4.4\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXV55VHnwjxy"
      },
      "source": [
        "# Normalize the values of all the scores\n",
        "df[cols_normalize] = df[cols_normalize].apply(lambda x:(x-x.min()) / (x.max()-x.min()))"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "SU6KOEYl1v31",
        "outputId": "f6d63c2c-16c5-460f-a433-27acbdd317c2"
      },
      "source": [
        "df.sample(10)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>STATUS</th>\n",
              "      <th>sEXT</th>\n",
              "      <th>sNEU</th>\n",
              "      <th>sAGR</th>\n",
              "      <th>sCON</th>\n",
              "      <th>sOPN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7289</th>\n",
              "      <td>\"We Americans think you have to accomplish eve...</td>\n",
              "      <td>0.817439</td>\n",
              "      <td>0.262857</td>\n",
              "      <td>0.453731</td>\n",
              "      <td>0.766197</td>\n",
              "      <td>0.938182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6300</th>\n",
              "      <td>I now have a master's degree - ABT (all but th...</td>\n",
              "      <td>0.386921</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.402985</td>\n",
              "      <td>0.507042</td>\n",
              "      <td>0.818182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5398</th>\n",
              "      <td>is working on new profile pic as E-28.</td>\n",
              "      <td>0.659401</td>\n",
              "      <td>0.314286</td>\n",
              "      <td>0.611940</td>\n",
              "      <td>0.718310</td>\n",
              "      <td>0.709091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5798</th>\n",
              "      <td>done with my paper finally =]]</td>\n",
              "      <td>0.536785</td>\n",
              "      <td>0.442857</td>\n",
              "      <td>0.507463</td>\n",
              "      <td>0.788732</td>\n",
              "      <td>0.454545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2930</th>\n",
              "      <td>so sick kill me now</td>\n",
              "      <td>0.659401</td>\n",
              "      <td>0.228571</td>\n",
              "      <td>0.567164</td>\n",
              "      <td>0.704225</td>\n",
              "      <td>0.563636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2112</th>\n",
              "      <td>Off to see whats left of the Beach Boys (I go ...</td>\n",
              "      <td>0.817439</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.752239</td>\n",
              "      <td>0.625352</td>\n",
              "      <td>0.781818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2129</th>\n",
              "      <td>Nothin's equivalent to a New York state of mind.</td>\n",
              "      <td>0.817439</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.752239</td>\n",
              "      <td>0.625352</td>\n",
              "      <td>0.781818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4363</th>\n",
              "      <td>was not impressed with Gossip Girl tonight. It...</td>\n",
              "      <td>0.850136</td>\n",
              "      <td>0.357143</td>\n",
              "      <td>0.417910</td>\n",
              "      <td>0.619718</td>\n",
              "      <td>0.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1429</th>\n",
              "      <td>never going home during the weekday ever again...</td>\n",
              "      <td>0.495913</td>\n",
              "      <td>0.671429</td>\n",
              "      <td>0.522388</td>\n",
              "      <td>0.211268</td>\n",
              "      <td>0.727273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1423</th>\n",
              "      <td>Went apple picking during hte weekend with fam...</td>\n",
              "      <td>0.495913</td>\n",
              "      <td>0.671429</td>\n",
              "      <td>0.522388</td>\n",
              "      <td>0.211268</td>\n",
              "      <td>0.727273</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 STATUS  ...      sOPN\n",
              "7289  \"We Americans think you have to accomplish eve...  ...  0.938182\n",
              "6300  I now have a master's degree - ABT (all but th...  ...  0.818182\n",
              "5398             is working on new profile pic as E-28.  ...  0.709091\n",
              "5798                     done with my paper finally =]]  ...  0.454545\n",
              "2930                                so sick kill me now  ...  0.563636\n",
              "2112  Off to see whats left of the Beach Boys (I go ...  ...  0.781818\n",
              "2129   Nothin's equivalent to a New York state of mind.  ...  0.781818\n",
              "4363  was not impressed with Gossip Girl tonight. It...  ...  0.600000\n",
              "1429  never going home during the weekday ever again...  ...  0.727273\n",
              "1423  Went apple picking during hte weekend with fam...  ...  0.727273\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3SVSvnH5l4w"
      },
      "source": [
        "df['lists'] = df[df.columns[1:6]].values.tolist()"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5o4fNS65nYX"
      },
      "source": [
        "df = df[['STATUS','lists']]"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "piMzn8uM5seq",
        "outputId": "c55782a3-a7d6-4921-ff34-14976dc11106"
      },
      "source": [
        "df.head(10)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>STATUS</th>\n",
              "      <th>lists</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>likes the sound of thunder.</td>\n",
              "      <td>[0.35967302452316074, 0.5, 0.44776119402985076...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>is so sleepy it's not even funny that's she ca...</td>\n",
              "      <td>[0.35967302452316074, 0.5, 0.44776119402985076...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>is sore and wants the knot of muscles at the b...</td>\n",
              "      <td>[0.35967302452316074, 0.5, 0.44776119402985076...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>likes how the day sounds in this new song.</td>\n",
              "      <td>[0.35967302452316074, 0.5, 0.44776119402985076...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>is home. &lt;3</td>\n",
              "      <td>[0.35967302452316074, 0.5, 0.44776119402985076...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>www.thejokerblogs.com</td>\n",
              "      <td>[0.35967302452316074, 0.5, 0.44776119402985076...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>saw a nun zombie, and liked it. Also, *PROPNAM...</td>\n",
              "      <td>[0.35967302452316074, 0.5, 0.44776119402985076...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>is in Kentucky. 421 miles into her 1100 mile j...</td>\n",
              "      <td>[0.35967302452316074, 0.5, 0.44776119402985076...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>was about to finish a digital painting before ...</td>\n",
              "      <td>[0.35967302452316074, 0.5, 0.44776119402985076...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>is celebrating her new haircut by listening to...</td>\n",
              "      <td>[0.35967302452316074, 0.5, 0.44776119402985076...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              STATUS                                              lists\n",
              "0                        likes the sound of thunder.  [0.35967302452316074, 0.5, 0.44776119402985076...\n",
              "1  is so sleepy it's not even funny that's she ca...  [0.35967302452316074, 0.5, 0.44776119402985076...\n",
              "2  is sore and wants the knot of muscles at the b...  [0.35967302452316074, 0.5, 0.44776119402985076...\n",
              "3         likes how the day sounds in this new song.  [0.35967302452316074, 0.5, 0.44776119402985076...\n",
              "4                                        is home. <3  [0.35967302452316074, 0.5, 0.44776119402985076...\n",
              "5                              www.thejokerblogs.com  [0.35967302452316074, 0.5, 0.44776119402985076...\n",
              "6  saw a nun zombie, and liked it. Also, *PROPNAM...  [0.35967302452316074, 0.5, 0.44776119402985076...\n",
              "7  is in Kentucky. 421 miles into her 1100 mile j...  [0.35967302452316074, 0.5, 0.44776119402985076...\n",
              "8  was about to finish a digital painting before ...  [0.35967302452316074, 0.5, 0.44776119402985076...\n",
              "9  is celebrating her new haircut by listening to...  [0.35967302452316074, 0.5, 0.44776119402985076..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oT6dfw02IYF",
        "outputId": "303da8a5-be22-412e-f2d8-2808b80b0ee3"
      },
      "source": [
        "device = \"cuda\" if cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMSeZYqd26H8"
      },
      "source": [
        "MAX_LEN = 512\n",
        "TRAIN_BATCH_SIZE = 8\n",
        "VALID_BATCH_SIZE = 8\n",
        "EPOCHS = 10\n",
        "LEARNING_RATE = 1e-5\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4haZ__w3I_O"
      },
      "source": [
        "import random\n",
        "\n",
        "seed_val = 42 #so our results/process is reproducible by whoever wants to reproduce\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val) #include for when using a GPU"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VvRko673LWz"
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.STATUS = dataframe.STATUS\n",
        "        self.targets = self.data.lists\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.STATUS)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        STATUS = str(self.STATUS[index])\n",
        "        STATUS = \" \".join(STATUS.split())\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            STATUS,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            pad_to_max_length=True,\n",
        "            return_token_type_ids=True,\n",
        "            truncation=True\n",
        "        )\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "        token_type_ids = inputs[\"token_type_ids\"]\n",
        "\n",
        "        return {\n",
        "            'ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
        "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
        "        }"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wq_qMrKs3ZoC",
        "outputId": "a75e47ad-07bc-4932-a73b-daa9d2062613"
      },
      "source": [
        "train_size = 0.8\n",
        "train_dataset=df.sample(frac=train_size,random_state=seed_val)\n",
        "test_dataset=df.drop(train_dataset.index).reset_index(drop=True)\n",
        "train_dataset = train_dataset.reset_index(drop=True)\n",
        "\n",
        "\n",
        "print(\"FULL Dataset: {}\".format(df.shape))\n",
        "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
        "\n",
        "training_set = CustomDataset(train_dataset, tokenizer, MAX_LEN)\n",
        "testing_set = CustomDataset(test_dataset, tokenizer, MAX_LEN)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FULL Dataset: (9917, 2)\n",
            "TRAIN Dataset: (7934, 2)\n",
            "TEST Dataset: (1983, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8y7CgKNE3Z93"
      },
      "source": [
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 4\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 1\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwxE0UiH512h",
        "outputId": "a005cbae-499f-48aa-fa52-c5dc43125100"
      },
      "source": [
        "class BERTClass(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BERTClass, self).__init__()\n",
        "        self.l1 = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.l2 = torch.nn.Dropout(0.3)\n",
        "        self.l3 = torch.nn.Linear(768, 5)\n",
        "    \n",
        "    def forward(self, ids, mask, token_type_ids):\n",
        "        _, output_1= self.l1(ids, attention_mask = mask, token_type_ids = token_type_ids)\n",
        "        output_2 = self.l2(output_1)\n",
        "        output = self.l3(output_2)\n",
        "        return output\n",
        "\n",
        "model = BERTClass()\n",
        "model.to(device)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BERTClass(\n",
              "  (l1): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (l2): Dropout(p=0.3, inplace=False)\n",
              "  (l3): Linear(in_features=768, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqNr_pQN56Co"
      },
      "source": [
        "def loss_fn(outputs, targets):\n",
        "    #  mean absolute error (MAE)\n",
        "    return torch.nn.L1Loss()(outputs, targets)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQiuHey76NAL"
      },
      "source": [
        "def train_fn(data_loader, model, optimizer, device, scheduler, epoch):\n",
        "  # Put the model in training mode\n",
        "  model.train()\n",
        "\n",
        "  # loop over all the batches\n",
        "  for i, d in enumerate(data_loader):\n",
        "    ids = d[\"ids\"]\n",
        "    token_type_ids = d[\"token_type_ids\"]\n",
        "    mask = d[\"mask\"]\n",
        "    targets = d[\"targets\"]\n",
        "\n",
        "    # convert to device type\n",
        "    ids = ids.to(device, dtype=torch.long)\n",
        "    token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
        "    mask = mask.to(device, dtype=torch.long)\n",
        "    targets = targets.to(device, dtype=torch.float)\n",
        "\n",
        "    # zero-grad the optimizer\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(\n",
        "        ids=ids,\n",
        "        mask=mask,\n",
        "        token_type_ids=token_type_ids\n",
        "    )\n",
        "    # calculate the loss\n",
        "    loss = loss_fn(outputs, targets)\n",
        "    if i % 5000==0:\n",
        "      print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
        "    # backward step the loss\n",
        "    loss.backward()\n",
        "    # step the optimizer\n",
        "    optimizer.step()\n",
        "    # step scheduler\n",
        "    scheduler.step()"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llQDVBpQ6Po2"
      },
      "source": [
        "def eval_fn(data_loader, model, device):\n",
        "  # put the model in eval mode\n",
        "  model.eval()\n",
        "  # initialize empty lists for targets and outputs\n",
        "  fin_targets = []\n",
        "  fin_outputs = []\n",
        "  \n",
        "  # no_grad to prevent unnecessary use of GPU memory\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      ids = d[\"ids\"]\n",
        "      token_type_ids = d[\"token_type_ids\"]\n",
        "      mask = d[\"mask\"]\n",
        "      targets = d[\"targets\"]\n",
        "  \n",
        "      # convert to device type\n",
        "      ids = ids.to(device, dtype=torch.long)\n",
        "      token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
        "      mask = mask.to(device, dtype=torch.long)\n",
        "      targets = targets.to(device, dtype=torch.float)\n",
        "  \n",
        "      outputs = model(\n",
        "          ids=ids,\n",
        "          mask=mask,\n",
        "          token_type_ids=token_type_ids\n",
        "      )\n",
        "  \n",
        "      # convert targets to cpu and extend the final list\n",
        "      targets = targets.cpu().detach()\n",
        "      fin_targets.extend(targets.numpy().tolist())\n",
        "      outputs = outputs.cpu().detach()\n",
        "      fin_outputs.extend(outputs.numpy().tolist())\n",
        "  return fin_outputs, fin_targets\n"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHSfydj16cEx"
      },
      "source": [
        "optimizer = AdamW(\n",
        "    model.parameters(),\n",
        "    lr=LEARNING_RATE, #2e-5 > 5e-5: A HYPERPARAMETER\n",
        "    eps=1e-8\n",
        ")\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=len(training_loader) * EPOCHS\n",
        ")"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQ-HjZhK6eCs",
        "outputId": "20546dd2-b1b3-4c18-94eb-794fc9405f8b"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  train_fn(training_loader,model, optimizer, device, scheduler, epoch)\n",
        "  outputs, targets = eval_fn(testing_loader, model, device)\n",
        "  print('Mean squared error: %.2f'\n",
        "        % mean_squared_error(targets, outputs))\n",
        "  print('Mean absolute error: %.2f'\n",
        "        % mean_absolute_error(targets, outputs))\n",
        "  print('Coefficient of determination: %.2f'\n",
        "        % r2_score(targets, outputs))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Loss:  0.46311861276626587\n",
            "Mean squared error: 0.05\n",
            "Mean absolute error: 0.17\n",
            "Coefficient of determination: 0.01\n",
            "Epoch: 1, Loss:  0.17312714457511902\n",
            "Mean squared error: 0.05\n",
            "Mean absolute error: 0.17\n",
            "Coefficient of determination: -0.00\n",
            "Epoch: 2, Loss:  0.15762853622436523\n",
            "Mean squared error: 0.05\n",
            "Mean absolute error: 0.17\n",
            "Coefficient of determination: 0.01\n",
            "Epoch: 3, Loss:  0.1380726546049118\n",
            "Mean squared error: 0.04\n",
            "Mean absolute error: 0.17\n",
            "Coefficient of determination: 0.02\n",
            "Epoch: 4, Loss:  0.16709309816360474\n",
            "Mean squared error: 0.04\n",
            "Mean absolute error: 0.16\n",
            "Coefficient of determination: 0.03\n",
            "Epoch: 5, Loss:  0.11789919435977936\n",
            "Mean squared error: 0.05\n",
            "Mean absolute error: 0.17\n",
            "Coefficient of determination: 0.00\n",
            "Epoch: 6, Loss:  0.14585135877132416\n",
            "Mean squared error: 0.05\n",
            "Mean absolute error: 0.17\n",
            "Coefficient of determination: -0.01\n",
            "Epoch: 7, Loss:  0.15716253221035004\n",
            "Mean squared error: 0.05\n",
            "Mean absolute error: 0.17\n",
            "Coefficient of determination: -0.00\n",
            "Epoch: 8, Loss:  0.10665245354175568\n",
            "Mean squared error: 0.05\n",
            "Mean absolute error: 0.17\n",
            "Coefficient of determination: 0.01\n",
            "Epoch: 9, Loss:  0.11461810022592545\n",
            "Mean squared error: 0.05\n",
            "Mean absolute error: 0.17\n",
            "Coefficient of determination: 0.01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wjk-obSQ7avv"
      },
      "source": [
        ""
      ],
      "execution_count": 70,
      "outputs": []
    }
  ]
}